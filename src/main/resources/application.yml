spring:
  application:
    name: ssf-graphql
  profiles:
    active: ${SPRING_PROFILES_ACTIVE:dev}
  # R2DBC configuration is handled separately via custom ReactiveDataSourceConfiguration bean.
  # Both JDBC and R2DBC are used: JDBC for blocking audit operations, R2DBC for reactive GraphQL endpoints.
  
  # ============================================================================
  # ACTIVE - JDBC MODE: Spring DataSource is configured for JDBC operations
  # (AuditService and synchronous repository access).
  # R2DBC is configured separately via custom ReactiveDataSourceConfiguration bean
  # for reactive GraphQL endpoints. Both coexist in the application.
  # ============================================================================
  datasource:
    url: jdbc:oracle:thin:@//${ORACLE_HOST:localhost}:${ORACLE_PORT:1521}/${ORACLE_DB:FREEPDB1}
    driver-class-name: oracle.jdbc.OracleDriver
    username: ${ORACLE_USER:APP_USER}
    password: ${ORACLE_PASSWORD:ssfpassword}
    hikari:
      connection-timeout: 30000
      maximum-pool-size: 20
      minimum-idle: 5
      auto-commit: true
      validation-timeout: 5000
      leak-detection-threshold: 60000
      max-lifetime: 1800000
      idle-timeout: 600000
      connection-test-query: SELECT 1 FROM DUAL
      data-source-properties:
        oracle.jdbc.fanEnabled: true
        oracle.jdbc.fastConnectionFailover: true
        oracle.net.CONNECT_TIMEOUT: 10000
        oracle.net.READ_TIMEOUT: 60000
        oracle.jdbc.implicitStatementCacheSize: 25
        oracle.jdbc.maxCachedBufferSize: 65536
  
  # ============================================================================
  # HIBERNATION/JPA CONFIGURATION: Only used if JDBC operations require JPA/Hibernate.
  # Currently R2DBC (reactive) is the primary data access layer for GraphQL endpoints.
  # This configuration is kept for potential JDBC-based JPA operations.
  # ============================================================================
  jpa:
    database-platform: org.hibernate.dialect.OracleDialect
    hibernate:
      ddl-auto: validate
    defer-datasource-initialization: false
    properties:
      hibernate:
        format_sql: true
        dialect: org.hibernate.dialect.OracleDialect
        jdbc:
          batch_size: 100
          fetch_size: 50
  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=500,expireAfterWrite=10m,recordStats
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD}
      timeout: 2000ms
      database: 0
    relational:
      # ANSI enables ANSI SQL identifier processing (which includes double-quote quoting for identifiers).
      # If you need to disable automatic identifier quoting entirely, use a custom R2DBC dialect decorator
      # that overrides getIdentifierProcessing() to return IdentifierProcessing.NONE.
      # See the r2dbcDialect() method in ReactiveDataSourceConfiguration.java for the decorator pattern.
      # Oracle treats lowercase identifiers as case-insensitive by default.
      naming-strategy: ANSI

# Cache Service Configuration
# Configures individual cache behavior (query result cache and session cache)
# Properties are read by CacheConfiguration class using Spring's @ConfigurationProperties
cache:
  config:
    # Query Result Cache: caches GraphQL/database query results
    query-result-cache:
      max-size: 1000                  # Maximum number of cache entries
      ttl-minutes: 15                 # Time-to-live in minutes before entries expire
    
    # Session Cache: caches user session data
    session-cache:
      max-size: 5000                  # Maximum number of cache entries
      ttl-minutes: 60                 # Time-to-live in minutes (1 hour)

server:
  port: 8443
  ssl:
    key-store: classpath:keystore.p12
    key-store-password: ${KEYSTORE_PASSWORD:changeit}
    key-store-type: PKCS12
    key-alias: ssf

# Batch operations configuration
batch:
  size: 200                          # Default batch size (100-500 based on memory profiling)
  max-retries: 3                     # Max retries with exponential backoff
  initial-retry-delay-ms: 100        # Initial retry delay in milliseconds
  memory-threshold-percent: 80       # Trigger batch size reduction at 80% heap usage

oracle:
  array:
    min-chunk-size: 500              # Lower bound chunk size under extreme memory pressure
    default-chunk-size: 2000         # Default associative array chunk size
    max-chunk-size: 10000            # Max chunk size when heap headroom allows
    eden-pause-threshold-percent: 80 # Pause producer when Eden occupancy exceeds this percent
    pause-duration-ms: 250           # Back-pressure duration when throttling array producers

query:
  streaming:
    fetch-size: 500                  # Default fetch size for cursor-based streaming
    max-fetch-size: 10000            # Upper bound fetch size when memory headroom allows
    idle-timeout-seconds: 30         # Cursor idle timeout to prevent orphaned streams

app:
  jwt:
    secret: ${JWT_SECRET}
  security:
    enable-default-user-role: true  # Enable default ROLE_USER for all authenticated users
  cors:
    allowed-origins: ${CORS_ALLOWED_ORIGINS:http://localhost:4200}  # Comma-separated list of allowed origins; configure per environment
  minio:
    url: http://localhost:9000
    access-key: ${MINIO_ACCESS_KEY}
    secret-key: ${MINIO_SECRET_KEY}
  r2dbc:
    # ACTIVE R2DBC configuration: Read by custom ReactiveDataSourceConfiguration bean
    # (Not Spring Boot's auto-configuration). These properties override any spring.r2dbc settings.
    # To switch R2DBC drivers, update the 'driver' property below (e.g., "postgresql", "mysql", "h2").
    host: ${ORACLE_HOST:localhost}
    port: ${ORACLE_PORT:1521}
    database: ${ORACLE_DB:FREEPDB1}
    username: ${ORACLE_USER:APP_USER}
    password: ${ORACLE_PASSWORD:ssfpassword}
    driver: oracle  # Set to "postgresql", "mysql", "h2", etc. to use a different R2DBC driver
    pool:
      min-idle: 10
      max-size: 80              # Keep aligned with Oracle capacity and <4x Hikari max
      queue-depth: 150          # Prevent deep backlog from exhausting DB sessions
      idle-timeout: PT30M
  datasource:
    enabled: true  # Enable JDBC DataSource for AuditService and other blocking operations

ssf:
  cache:
    default-max-age: 3600            # Default Cache-Control max-age in seconds (1 hour)

# Trace Configuration
# PII Tracing: By default, userId and client_ip are hashed (SHA-256) to avoid raw PII in traces
# 
# IMPORTANT: PII hashing is REQUIRED for production deployments.
# The salt must be:
#   - Non-empty and at least 16 characters long
#   - Mix of uppercase, lowercase, digits, and special characters (validated at startup)
#   - Loaded from a secure secrets manager (AWS Secrets Manager, HashiCorp Vault, Azure KeyVault, etc.)
#   - NEVER hardcoded in application properties or source control
#
# Configuration:
#   1. RECOMMENDED (Secrets Manager):
#      - Store salt in AWS Secrets Manager / Vault / etc.
#      - Inject via TRACE_PII_SALT environment variable at runtime
#   2. ALTERNATIVE (Environment Variable):
#      - Set TRACE_PII_SALT=<strong-salt> at container/pod startup
#   3. NOT RECOMMENDED (Application Properties):
#      - trace.pii-salt: Can be set in properties files for development ONLY
#
# Example strong salt (for development testing only):
#   trace.pii-salt: "DevTest@2024#Salt!Secure"
#
# To disable PII hashing and include raw values (NOT recommended):
#   trace.include-pii: true
#
trace:
  includePii: ${TRACE_INCLUDE_PII:false}     # Include raw PII in traces (default: false = hash)
  piiSalt: ${TRACE_PII_SALT:}                # REQUIRED if include-pii is false. Load from secrets manager.

management:
  endpoints:
    web:
      exposure:
        include: ${MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE:health,metrics}
  endpoint:
    health:
      show-details: when-authorized
  metrics:
    enable:
      cache: true
      jvm: true
      process: true
      system: true

# OpenTelemetry Configuration for Distributed Tracing
otel:
  exporter:
    otlp:
      # Endpoint for OTLP/gRPC exporter (Jaeger or Tempo backend)
      # Default: http://localhost:4317 for local development
      # Environment: OTEL_EXPORTER_OTLP_ENDPOINT
      endpoint: ${OTEL_EXPORTER_OTLP_ENDPOINT:http://localhost:4317}
  service:
    # Service name for tracing - must match docker-compose and OtelConfig.java
    # Explicit default: ssf-graphql (not fallback to spring.application.name)
    # Can be overridden via OTEL_SERVICE_NAME environment variable
    name: ${OTEL_SERVICE_NAME:ssf-graphql}
  traces:
    # Tracer configuration
    exporter: otlp  # Use OTLP exporter for Jaeger/Tempo
    sampler:
      # Sampling strategy for traces
      # - always_on: Always sample (high volume, not production)
      # - always_off: Never sample
      # - probability: Sample based on probability (0.0-1.0)
      type: ${OTEL_TRACES_SAMPLER:probability}
      arg: ${OTEL_TRACES_SAMPLER_ARG:0.1}  # Sample 10% of traces by default

schema:
  bootstrap:
    enabled: true
    continue-on-error: true

# Logging configuration - production defaults
# For verbose DEBUG/TRACE logging, use: --spring.profiles.active=dev
logging:
  level:
    # Production defaults: INFO/WARN for external libraries
    org.springframework.data.r2dbc: INFO
    org.springframework.jdbc: WARN
    org.springframework.data.jpa: WARN
    oracle.r2dbc: INFO
    oracle.jdbc: WARN
    # Redis operations
    com.rcs.ssf.http.filter.CompressionFilter: INFO
    com.rcs.ssf.service.DynamicCrudService: INFO      # Oracle streaming logs
    com.rcs.ssf.config.MinioConfig: INFO              # MinIO metrics/interceptors
    org.springframework.data.redis: INFO    
    # MinIO operations
    io.minio: INFO
    # Custom application logs - INFO for production
    com.rcs.ssf: INFO
    # Suppress DBMS_MONITOR warnings when package is unavailable
    '[com.rcs.ssf.dynamic.PlsqlInstrumentationSupport]': WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/ssf-application.log
    max-size: 10MB
    max-history: 30